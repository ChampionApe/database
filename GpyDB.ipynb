{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efe2704a-4d1a-4fe1-a9ae-615dc4e8203c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyDatabases.gpyDB.gpyDB import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2252d5f-7f64-47e4-9c21-0d52ea0d7850",
   "metadata": {},
   "source": [
    "## 1. GpyDB tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cd866a-cc45-4f4a-b980-557b6bbc0935",
   "metadata": {},
   "source": [
    "### 1.1. Init, load, write, export"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf5dd95-2e86-4eb5-9a7d-bad30fcecb33",
   "metadata": {},
   "source": [
    "*Init database from gdx file*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37720818-40c0-433b-b102-d5fcf9575c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = GpyDB(name = 'test1',\n",
    "           ws = os.path.join(os.getcwd(), 'workFolder'), \n",
    "           db = os.path.join(os.getcwd(), 'testdata','test_size1000.gdx'),\n",
    "           **{'data_folder': os.path.join(os.getcwd(), 'testdata')})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402ee935-4391-42ea-bd5a-38bbdb422753",
   "metadata": {},
   "source": [
    "*Merge internal with ```priority = 'second'```:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d57279f-b165-4a7f-b818-0dcdb88ac340",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.mergeInternal(priority = 'second') # overwrite existing symbols\n",
    "db.database.export('test1.gdx') # test that exports look as expected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8b88fd-9cad-4a56-a334-db25e4c4a951",
   "metadata": {},
   "source": [
    "*Merge internal with ```merge = 'replace'```: This creates a new ```GamsDatabase``` in the workspace, where everything is added to:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5b4485a-64b8-4109-889b-55a45315ac2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test1': 0, 'test2': 0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.mergeInternal(priority = 'replace', name = 'test2')\n",
    "db.database.export('test2.gdx')\n",
    "db.ws._gams_databases # the original workspace still contains the original database, but the main db in the GpyDB class is the new one 'test2'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f88f4f9-e0bc-453e-9c6b-299b2719719f",
   "metadata": {},
   "source": [
    "*Store as pickle (with default options):*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c64d5a78-1df8-4403-acf1-f96cac7a047f",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.export(name = None, repo = None) # defaults to self.name and self.exportSettings['data_folder']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1c4ced-7b8e-4610-a60c-9d26739219cf",
   "metadata": {},
   "source": [
    "*Read in again from pickle, initialize in existing workspace:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e1f5b4b-27d3-40b0-991d-e0ae710e3e25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbPickled = GpyDB(pickle_path = os.path.join(db.exportSettings['data_folder'], db.name), ws = db.ws)\n",
    "dbPickled.ws is db.ws"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d366fd18-a18e-4c6f-8b53-50c89b508d5d",
   "metadata": {},
   "source": [
    "*As a default, the gdx file is **not** stored when exporting as pickle, only the ```self.SeriesDB``` that contains python versions of the database. We can change this by adjusting the ```self.exportSettings```:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2333576-c246-4e45-bdd2-99a9005ec5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.exportSettings['dropattrs'] = [k for k in db.exportSettings['dropattrs'] if k !='database'] # remove 'database' from list of attributes NOT to keep\n",
    "db.export(name = 'GpyDBwithGdx') # export with gdx database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d084f27-4f62-4137-be0b-6fb3f88320fb",
   "metadata": {},
   "source": [
    "*As the gdx database is not pickleable, it is written to a separate file in the data folder and loaded again if we pickle this:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a027bd6-7d2d-401b-9852-439554315aa4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alias_set': <Swig Object of type 'void *' at 0x0000024527BD9CB0>,\n",
       " 'alias_map2': <Swig Object of type 'void *' at 0x0000024527BD9C50>,\n",
       " 'i': <Swig Object of type 'void *' at 0x0000024527BD8DB0>,\n",
       " 'j': <Swig Object of type 'void *' at 0x0000024527BD9C20>,\n",
       " 'alias_': <Swig Object of type 'void *' at 0x0000024527BD9560>,\n",
       " 'map': <Swig Object of type 'void *' at 0x0000024527BD9CE0>,\n",
       " 'var': <Swig Object of type 'void *' at 0x0000024527BD9D70>,\n",
       " 'var1d': <Swig Object of type 'void *' at 0x0000024527BD9DA0>,\n",
       " 'param': <Swig Object of type 'void *' at 0x0000024527BD9DD0>,\n",
       " 'scalar': <Swig Object of type 'void *' at 0x0000024527BD9E00>,\n",
       " 'pscalar': <Swig Object of type 'void *' at 0x0000024527BD9E30>,\n",
       " 'subset': <Swig Object of type 'void *' at 0x0000024527BD9E60>}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbPickled_v2 = GpyDB(pickle_path = os.path.join(db.exportSettings['data_folder'], 'GpyDBwithGdx'))\n",
    "dbPickled_v2.gmd.symbols # symbols from database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d109690-c03a-4f83-b14f-6a5791db9e5c",
   "metadata": {},
   "source": [
    "*Initialize a new GpyDB from this one: This copies all attributes from the original, but allows you to adjust the workspace:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bdcd8c3-aaac-4c61-b89f-9ce90238826e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbFromGpyDB = GpyDB(db = db, **{'name': 'fromGpyDB'}, ws = db.work_folder) # copy the database, but work in a new GamsWorkspace\n",
    "dbFromGpyDB.ws is db.ws"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f174eea-4855-422e-a29b-6f44933c4da6",
   "metadata": {},
   "source": [
    "### 1.2. Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82339e96-8f33-4ca1-9b76-9b10d375fbda",
   "metadata": {},
   "source": [
    "#### Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07d6429a-7ddf-4c8e-a68e-d760fcf714ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'j': Index(['jj'], dtype='object', name='alias_map2')}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.aliasDict # map from original set to aliases\n",
    "# db.aliasDict0 # includes the original set in the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b03aa9e-987f-4215-b2ea-a2a86b8e6339",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'jj'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.alias_notin_db # what aliases are not also included in the database as symbols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1eef607-78a9-487d-8f1b-38815218aed1",
   "metadata": {},
   "source": [
    "#### Get/set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260d7958-f136-4839-94dc-997727e1a91e",
   "metadata": {},
   "source": [
    "Add symbols to the ```self.series``` database using ```self.__setitem__``` method. This automatically calls the ```gpy``` class, so we can set items either using their pandas/python pendant or the gpy symbols:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5dac6765-884b-4c2b-bc5b-2db809fac296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['set', 'subset', 'map']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db['newSet'] = pd.Index([0,1], name = 'newSet')\n",
    "db['newSubset'] = pd.Index([0], name = 'newSet') # If the domain of the index does not coincide with the given name in the database --> subset\n",
    "db['newMap'] = pd.MultiIndex.from_product([db('j'), db('newSet')]) # the .__call__() method accesses the pandas/python part of the symbol directly\n",
    "[db[k].type for k in ('newSet','newSubset','newMap')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b783c45-eae1-488f-8bf2-2194f8d4be11",
   "metadata": {},
   "source": [
    "The ```self.__call__``` method accesses the ```self.vals``` part of the ```gpy``` symbols, i.e.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6b6c5f6-b47d-413d-84f8-25f178437036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db['newSet'].vals is db('newSet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2086f96-3045-44ec-aa5f-a90891fbbff7",
   "metadata": {},
   "source": [
    "The ```self.__call__``` and ```self.__getitem__``` methods allows us to access aliased sets as well. For instance, the alias ```'jj'``` is not defined as a symbol in the ```self.series``` database, but calling this we access the original set ```'j'```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "441317ba-1f93-44da-ae6f-fe678182cd29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db['jj'] is db['j'] # the self.__getitem__ method accesses the parent set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09837c65-e26d-421f-b7e5-edc1358892cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([  1,   0,   2,   3,   4,   5,   6,   7,   8,   9,\n",
       "       ...\n",
       "       990, 991, 992, 993, 994, 995, 996, 997, 998, 999],\n",
       "      dtype='int32', name='jj', length=1000)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db('jj') # the get method accesses parent set + adjusts name of index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea58c00-be1a-4c9c-beca-bb6bfdbc1eef",
   "metadata": {},
   "source": [
    "#### Alias methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f65bbed-c62a-4d06-8a85-6e4a3058f3f2",
   "metadata": {},
   "source": [
    "The method ```self.alias(x, idx = 0)```: \n",
    "* If ```x``` is not aliased, but a set and ```idx=0```: ```return x```.\n",
    "* If ```x``` is either an aliased set or a parent set to one, this returns the parent set when ```idx = 0``` as default, while for ```idx>0``` this returns the aliased sets (idx is passed to ```self.aliasDict0```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a536262e-4e52-4adc-a9b5-fec94e2228af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.alias('i') # 'i' is a set, so this works even though it is not aliased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6acc8d0-b4b1-4474-bf46-3d6b59738046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This trows a TypeError, because i is not alised\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    db.alias('i', idx = 1)\n",
    "except TypeError:\n",
    "    print('This trows a TypeError, because i is not alised')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bdd01a44-982a-4ea2-a7d3-06242fea9b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'j' == db.alias('j') == db.alias('jj') # aliased sets return the same object no matter if it is a parent set or the aliased one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee795788-c7d4-4ede-9a79-c760bb12e70d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'jj' == db.alias('j',idx = 1) == db.alias('jj',idx=1) # if idx = 1 this returns the first aliased set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dca1cc-a7ce-447f-a7c4-bc0abd932e74",
   "metadata": {},
   "source": [
    "#### Other"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6a85da-680e-48aa-88f7-cc0d715c8b88",
   "metadata": {},
   "source": [
    "The method ```self.getTypes(types)``` returns a subset of the ```self.symbols``` property based on the types (iterative arg.) that are passed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7d35246-5408-4ac0-ad03-08b648b37d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alias_set': <pyDatabases.gpyDB.database.gpy at 0x24527bba850>,\n",
       " 'alias_map2': <pyDatabases.gpyDB.database.gpy at 0x24527b9c4d0>,\n",
       " 'i': <pyDatabases.gpyDB.database.gpy at 0x24527b83f50>,\n",
       " 'j': <pyDatabases.gpyDB.database.gpy at 0x24527bbffd0>,\n",
       " 'newSet': <pyDatabases.gpyDB.database.gpy at 0x24527bc43d0>}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.getTypes(['set']) # get sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f455db6b-b5cd-4839-a708-0beccfa1f433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alias_set': <pyDatabases.gpyDB.database.gpy at 0x24527bba850>,\n",
       " 'alias_map2': <pyDatabases.gpyDB.database.gpy at 0x24527b9c4d0>,\n",
       " 'i': <pyDatabases.gpyDB.database.gpy at 0x24527b83f50>,\n",
       " 'j': <pyDatabases.gpyDB.database.gpy at 0x24527bbffd0>,\n",
       " 'scalar': <pyDatabases.gpyDB.database.gpy at 0x245277a7190>,\n",
       " 'newSet': <pyDatabases.gpyDB.database.gpy at 0x24527bc43d0>}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.getTypes(['set','scalarVar']) # get scalar variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46a1b03-d43d-44b3-b28d-d809f090f4a9",
   "metadata": {},
   "source": [
    "The method ```self.copy(dropattrs=None, **kwargs)```: Creates a copy of the database. The ```kwargs``` are added to the ```self.__init__``` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c5b3d86a-b5fb-4c58-85a2-c74108a97677",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbcopy = db.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888d3865-3d75-47b9-9710-325341ec4f9f",
   "metadata": {},
   "source": [
    "The method ```self.domainsUnique(x)``` returns the unique domains a symbol is defined over, replacing aliased sets with their parent sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77ff7cae-9e49-49fe-b4f6-e59516475ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'j']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.domainsUnique('var')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1f2254-5b01-4d2f-81ae-3c5eeaaea751",
   "metadata": {},
   "source": [
    "The method ```self.varDom(set_, types = None)``` returns a dictionary with keys = sets and aliases and values = list of symbols of 'types' that are defined over these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d54d018-0c36-44db-a51a-985cc33d26d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'i': ['var', 'var1d', 'param']}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.varDom('i') # the default is to look for types ['var','par']. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6b677150-0a7e-49be-aadd-e1762c71f2b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'i': ['map', 'var', 'var1d']}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.varDom('i', types = ['var','map'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa01031-2df6-4aa6-9755-2ffb35089706",
   "metadata": {},
   "source": [
    "## 2. Other classes from ```gpyDB```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7da6f7-c392-467b-acd1-c46ea2ad75f0",
   "metadata": {},
   "source": [
    "### 2.1. ```DbFromExcel```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fb8a4c-e006-4122-9e38-02affe3be739",
   "metadata": {},
   "source": [
    "Small calss that reads in excel data as dicts of ```gpy``` symbols. Data has to be arranged in a particular way for this to work. Examples are given in the ```test_read.xlsx``` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1ed3283d-c36a-49a2-aab6-49c7bd271ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = os.path.join(os.getcwd(), 'testdata','test_read.xlsx')\n",
    "kwargs = {k: f'_{k}' for k in ('set','subset','map','var','scalarVar','var2D')}\n",
    "db_ = DbFromExcel.dbFromWB(file, kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28deac7e-6c19-4b05-9984-b4a31d638f11",
   "metadata": {},
   "source": [
    "The kwargs indicate key = method to apply when reaing the data, value = sheet or list of sheets to iterate through. The syntax for loading several sheets calling the same method is done by adding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b1c5082-38d8-4dfa-857d-e4ee9af57003",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs['set'] = ['_set','extraset'] # iterable of sheetnames\n",
    "db_ = DbFromExcel.dbFromWB(file, kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b2a3c6-f136-46e1-ba04-23cfd7965b69",
   "metadata": {},
   "source": [
    "### 2.2. ```AggDB```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d8c76a-796f-4e5f-89b0-1b7cc9c9634e",
   "metadata": {},
   "source": [
    "Small class that can be used to aggregate the database. The class contains a handfull of methods that are called when doing the \"main\" aggregation method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff458126-08d8-4243-bb14-339a58cca512",
   "metadata": {},
   "source": [
    "*Re-read the clean database version:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5cdca3e5-a950-4533-8272-7d80619d0059",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = GpyDB(name = 'test1',\n",
    "           ws = os.path.join(os.getcwd(), 'workFolder'), \n",
    "           db = os.path.join(os.getcwd(), 'testdata','test_size1000.gdx'),\n",
    "           **{'data_folder': os.path.join(os.getcwd(), 'testdata')})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996c5d49-23d8-4f88-9c46-e5752ad1ef82",
   "metadata": {},
   "source": [
    "To make sure that our alias method work, define a couple of extra symbols over the alias as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "782f3e20-74a4-4c7e-abca-6d5a72cbbc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "jj = pd.Index(np.roll(db('map').get_level_values('j').values, 1), name = 'jj')\n",
    "db['mapWithAlias'] = pd.MultiIndex.from_arrays([db('map').get_level_values(0), db('map').get_level_values(1), jj]).sort_values()\n",
    "db['subsetWithAlias'] = jj[0:2].rename('subsetWithAlias')\n",
    "db['varWithAlias_1'] = pd.Series(1.5, index = db('mapWithAlias')) \n",
    "db['varWithAlias_2'] = pd.Series(0.5, index = adj.AdjAliasInd(db('map'), alias = {'j':'jj'})[0:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52582559-65f8-4238-8753-f63597eeb8c4",
   "metadata": {},
   "source": [
    "#### 2.2.1. Update set elemetns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e15bf23-0f31-4df1-8e2c-d7a3f3d9a795",
   "metadata": {},
   "source": [
    "The first method takes a mapping from old to new set values and updated the values in indices used throughout the database. We note that this is generally *not* used to aggregate databases, i.e. we prefer not to use a mapping that reduces the number of set elements, but merely renames them. However, the method does work even if this is the case. For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fd803eb8-f9b6-4e52-b399-298ed4515c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "setName = 'j'\n",
    "ns = {1: 0, 2:0, 3:0}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46fcbec-41d9-4302-acbc-157a375c2d17",
   "metadata": {},
   "source": [
    "There are two things to be aware of here: \n",
    "* We may use ```rul = True``` if we want to remove unused levels in all indices before mapping to the new values (see ```pd.Index.remove_unused_levels```).\n",
    "* If the namespace mapping (```ns```) that we apply implies non-unique combinations, we generally ensure that all sets, subsets, and mappings are forced to unique combinations, whereas we keep all records of parameters and variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "089272fe-1157-4d86-b47e-60f659820360",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_newSetValues = AggDB.updSetElements(db.copy(), setName, ns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eff0edc-e72d-499a-adc0-d5dfcb0b0a92",
   "metadata": {},
   "source": [
    "So, the mapping 'map' includes fewer elements than before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "83b78600-2be4-41f7-b4af-e63d1599358d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(db('map'))-len(db_newSetValues('map'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c422f75-a72f-41cb-8045-53b751fba2c0",
   "metadata": {},
   "source": [
    "Whereas the variable 'var' that is defined over the same mapping does not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "da24fe85-253d-4d35-90b1-f39b28063813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(db('var'))-len(db_newSetValues('var'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12672e13-ee6b-4788-b094-7a35da3ca448",
   "metadata": {},
   "source": [
    "#### 2.2.2. Update set names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02999ff1-8d52-4049-bdcb-c7835bf6f3cc",
   "metadata": {},
   "source": [
    "This method changes the set name used throughout all symbols. For instance, let us say that we want to rename the set $i$ to $k$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "81279b1d-dc54-4179-8761-2344ffe06e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = {'i':'k'}\n",
    "db_newSetNames = AggDB.updSetNames(db.copy(), ns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de99f060-20dc-404f-8386-3e5c24fbbe46",
   "metadata": {},
   "source": [
    "#### 2.2.3. Update sets from symbols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92add1c1-9a6b-4608-aa58-5a1ea8a735cf",
   "metadata": {},
   "source": [
    "This infer set values from the symbols that are otherwise defined in the database. This can be used if we load information e.g. on variables or parameters, and subsequently want to define the underlying sets as well (e.g. because GAMS usually requires this):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1a737065-6a04-433f-ab86-8518345c9568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyDatabases.gpyDB.gpyDB.GpyDB at 0x24527bc7190>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_updSetsFromSyms = db.copy() # create copy\n",
    "AggDB.updSetsFromSyms(db, types = ['var','par'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212c17cd-3fd2-46d7-a4e3-922d3b8ff935",
   "metadata": {},
   "source": [
    "We have the following options when doing this:\n",
    "* ```types = None```: The type of symbols to infer set definitions from. When ```None``` this defaults to ```['var','par']``` definitions.\n",
    "* ```clean = True```: If ```True```, it starts by empyting all set, subset, and map definitions.\n",
    "* ```clean_alias = True```: Reset alias settings (stored in ```self.db['alias_']``` multiindex).\n",
    "* ```ignore_alias = False```: If ```False```, this does not add aliased sets to the database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f51665-315c-404d-ae58-f41f7926ae49",
   "metadata": {},
   "source": [
    "#### 2.2.4. Subset database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7ec856-7d60-42c6-8aaf-09006dacdbf2",
   "metadata": {},
   "source": [
    "This adjusts all symbols in the database based on an index, we provide. For instance, say that we want to exclude some elements from the $j$ index across all symbols:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f78e1e5c-ca8f-4c4f-b54f-2b8bcbc4a2ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "i  j\n",
       "1  1    10.0\n",
       "   0    10.0\n",
       "   2    10.0\n",
       "Name: var, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_subsetDB = AggDB.subsetDB(db.copy(), pd.Index(db('j')[0:3])) # remove all but the first 4 elements in the 'j' index - for all symbols in the database\n",
    "db_subsetDB('var') # all symbols including e.g. variables are \"subsetted\" in this manner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666980b2-3e37-41e7-b23d-2f48792f5cc0",
   "metadata": {},
   "source": [
    "#### 2.2.5. Aggregate database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70dec98a-8fd3-47ad-b77a-5cb5bffc2a91",
   "metadata": {},
   "source": [
    "This aggregates all symbols according to a mapping from old set elements to new ones. Contrary to the method ```updSetElements```, this method is designed to change the number of set elements in the various indices, and to handle non-unique combinations of variable entries etc.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3c893b-0515-4d38-9f6b-1ce8d1112a83",
   "metadata": {},
   "source": [
    "Say, for instance, that we want to aggregate the set $j$ into intervals of 10's:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "97c274cd-0ec2-4823-ba9c-1048bc18887e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = pd.MultiIndex.from_arrays([db('j'), np.round(db('j')+5.1, -1).astype(int).rename('agg_j')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d855fd-57d3-4942-bff9-311ca09c3827",
   "metadata": {},
   "source": [
    "We need to decide what to do with the variables that are now aggregated. Currently, we have implemented a handful of methods: ```Sum, Mean, WeightedSum, SplitDistr, Lambda```. As a default, the method will use the simple ```Sum``` method. We can adjust this by specifying a dictionary as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1bd6ce88-e440-497e-a8df-8fbecc2d2861",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggLike = {'var': {'func': 'Mean', 'kwargs': {}}}\n",
    "db_agg = AggDB.aggDB(db.copy(), mapping, aggBy = None, replaceWith = None, aggLike = aggLike) # default options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11880835-9d0e-44c5-ad90-16ab98150fa4",
   "metadata": {},
   "source": [
    "We can also use this, in principle, to disaggregate a database. Let us, for simplicity, assume that we want to split up a single set element in the $j$ set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a850efc8-35b8-43c0-b3de-7d32366ed455",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = pd.MultiIndex.from_arrays([db('j'), db('j').rename('disagg_j')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6cde72-c733-4940-bb20-7b6a17c1ebe3",
   "metadata": {},
   "source": [
    "## 3. Methods from ```gpyDB.database.py```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f249481-5c55-4e6c-8498-2e7102207b08",
   "metadata": {},
   "source": [
    "This includes classes that transfers data between Python (```gpy```) and GAMS (```GamsDatabase, Gmd```). Most notably, we have the following classes:\n",
    "1. ```gpy```: Customized symbol class that ```GpyDB``` draws on.\n",
    "2. ```readGmd``` (or ```gpyFromGmd```): Transfer data from ```GamsDatabase``` to ```gpy```-like symbols. Draws on the fast methods from ```gams.core.gmd```.\n",
    "3. ```gmdFromGpy```: Transfer data from ```gpy``` format to ```GamsDatabase``` symbols. Draws on the fast methods from ```gams.core.gmd```.\n",
    "4. ```gpyFromGt```: Transfer data using ```gams.transfer.Container``` to ```gpy```-like symbols. Pretty fast (not as fast as ```readGmd``` though). \n",
    "5. ```gtFromGpy```: Populate a ```gams.transfer.Container``` database using ```gpy``` symbols.\n",
    "6. ```MergeSyms```: Merge symbols from gams or gpy databases.\n",
    "\n",
    "As GAMS models rely on ```GamsDatabase```, however, we will rarely use classes 5-6."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4ecce3-9779-4901-ad11-f8b613691efd",
   "metadata": {},
   "source": [
    "Merge methods:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81315e2f-3a8a-4747-bd2b-061dd5760d59",
   "metadata": {},
   "source": [
    "```python\n",
    "class readGmd:\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbf99d2-c185-4945-a8e9-ce6030a7eb05",
   "metadata": {},
   "source": [
    "Methods for reading a gams database (```self.database``` from the ```GpyDB``` instance) to dict of ```gpy``` symbols. This is class that is used when initializing ```GpyDB``` from a GamsDatabase.\n",
    "* The ```self.__call__``` method returns a dictionary of ```gpy``` symbols that represents the entire database.\n",
    "* The ```self.gpy(symbol)``` method returns a ```gpy``` from the symbol input (needs to be a ```Swig Object```). These symbols can be accessed in dictionary from ```self.symbols```."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032dff54-2d88-442b-930f-f25e24103efd",
   "metadata": {},
   "source": [
    "```python\n",
    "class gpyFromGt:\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054cbd51-f3c9-4cc9-81fe-81c1817f111c",
   "metadata": {},
   "source": [
    "Does the same thing as ```readGmd```, but for a ```gams.transfer.Container``` database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c10e506-7afb-454d-ac5f-994e5d0e643b",
   "metadata": {},
   "source": [
    "```python\n",
    "class gtFromGpy:\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f96596e-27fb-44df-b10b-397c8b2a5f2a",
   "metadata": {},
   "source": [
    "Inverse to ```gpyFromGt```."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9129d58e-5448-413a-998c-c71dfe6ca1e6",
   "metadata": {},
   "source": [
    "```python\n",
    "class gmdFromGpy\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789b2f0f-7c6d-406f-b46d-65c6fb62b320",
   "metadata": {},
   "source": [
    "Inverse methods to ```readGmd``` class. This has method for adding symbols to GamsDatabases, adjusting them, and adding-or-merging.\n",
    "* ```self.db(dbGpy, dbGmd, g2np, merge = True)```: Merge symbols from dbGpy (populated with ```gpy``` symbols) into dbGmd (```GamsDatabase```).\n",
    "* ```self.initDb(dbGpy, dbGmd, g2np)```: Like ```self.db```, but it assumes that ```dbGmd``` is empty / does not have any of the symbols from ```dbGpy``` before doing so.\n",
    "* ```init(symbol, db)```, ```add(symbol, db, g2np)```, ```adjust(symbol, db, g2np)```: Static methods that initialize, add, and adjust symbols in a database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d82c5d3-f3c5-4a54-9683-f5eb46c5229f",
   "metadata": {},
   "source": [
    "### 3.1. MergeSyms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e55e70-eb70-4c12-b7f8-a50db663d05e",
   "metadata": {},
   "source": [
    "The class is set up to merge symbols from gpy or gmd database types. The method ```MergeSyms.merge``` is a robust version that works with the four combinations. \n",
    "\n",
    "**Note that all these methods work *inplace* meaning that you will alter the symbols along the way**. (*This is by design, as the symbols from the gmd database only exists in conjunction with the database itself - thus returning a copy is meaningless unless we initialize an entire new database*)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7d6797-588d-451e-a71d-63622d13e4c5",
   "metadata": {},
   "source": [
    "*Merge two gpy symbols:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "216b5872-75f5-42fe-891f-7bc5781a87ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyDatabases.gpyDB.database.gpy at 0x24527c67b90>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MergeSyms.merge(db['var'], db['param'], priority = 'first') # merge the two, and keep values from the first symbol if they overlap\n",
    "# MergeSyms.merge(db['var'], db['param'], priority = 'second') # merge the two, and keep values from the second symbol if they overlap\n",
    "# MergeSyms.merge(db['var'], db['param'], priority = 'replace') # merge the two and only use values from the second symbol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f2650b-9391-495f-baf5-be5005af481f",
   "metadata": {},
   "source": [
    "*Merge gpy and gmd symbol:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "389a0804-ae8e-47f4-807a-e2af16838639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyDatabases.gpyDB.database.gpy at 0x24527c67b90>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MergeSyms.merge(db['var'], db.gmd, name = 'var', priority = 'first') # merge the two and keep values from gpy symbol if they overlap\n",
    "# MergeSyms.merge(db['var'], db.gmd, name = 'var', priority = 'second') # merge the two and keep values from gmd symbol if they overlap\n",
    "# MergeSyms.merge(db['var'], db.gmd, name = 'var', priority = 'replace') # merge the two and only use values from the second symbol "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad0e7d1-3ccf-4f51-b7c6-0fc4d4239107",
   "metadata": {},
   "source": [
    "*Merge gmd and gpy symbols:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "210aba5b-af08-4804-b90c-96506b593202",
   "metadata": {},
   "outputs": [],
   "source": [
    "MergeSyms.merge(db.gmd, db['var'], name = 'var', priority = 'first')\n",
    "# MergeSyms.merge(db.gmd, db['var'], name = 'var', priority = 'second')\n",
    "# MergeSyms.merge(db.gmd, db['var'], name = 'var', priority = 'replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f465619c-7938-4b4b-8f2a-3f1e2471bd0b",
   "metadata": {},
   "source": [
    "*Merge gmd and gmd symbols:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f9c80f2c-8819-4afa-9862-5b39a5cc4317",
   "metadata": {},
   "outputs": [],
   "source": [
    "MergeSyms.merge(db.gmd, db.gmd, name = 'var', priority = 'first')\n",
    "# MergeSyms.merge(db.gmd, db.gmd, name = 'var', priority = 'second')\n",
    "# MergeSyms.merge(db.gmd, db.gmd, name = 'var', priority = 'replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd1f14f-80c8-40fd-a0d1-dc50b5c1a1b3",
   "metadata": {},
   "source": [
    "### 3.2. MergeDbs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cf7b14-d059-437f-ad38-93dcf6633c36",
   "metadata": {},
   "source": [
    "The class merges databases that are of the types ```GpyDB, SeriesDB, dict, readGmd``` (the dict should be a dictionary of ```gpy``` symbols). Once again, the method ```MergeDbs.merge``` is a version that works with combinations of the four. As with ```MergeSyms``` these methods all work inplace as well, i.e. we alter the databases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c45c058-fe25-4088-ad43-c7b241054f38",
   "metadata": {},
   "source": [
    "*This is a very simple test of whether the merges work, as they are all essentially the same database (almost at least, the code above may have altered them slightly)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f7748453-ab9d-47b3-bd21-dc6f2e71ab47",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbs = [db, db.series, db.series.database, db.gmd]\n",
    "for dbi, dbii in itertools.product(dbs, dbs):\n",
    "    MergeDbs.merge(dbi,dbii)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2952c8f-2f57-4194-a263-4df40505d16f",
   "metadata": {},
   "source": [
    "## 4. Methods from ```auxfuncs.py```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141605f6-d18a-45d2-8fde-19621343a52e",
   "metadata": {},
   "source": [
    "This section is loaded in all other modules and contains basic methods. It includes:\n",
    "* ```OrdSet``` class: Custom class with ordered sets.\n",
    "* ```adj``` class: Provides methods to (i) subset pandas with nested conditions, (ii) adjust indices with lags or aliased sets.\n",
    "* ```adjMultiIndex``` class: Methods used to adjust symbols defined over multiindices. This includes (i) broadcasting, (ii) applying multiindices to symbols that matches/expands sets they are defined over, (iii) appending symbols with pre-specified grids.\n",
    "* ```readSetsFromDb``` method: Reads in and defines sets/indices based on the ```pd.Index``` objects that variables/mappings are defined over."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
