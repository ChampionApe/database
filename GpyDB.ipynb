{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8fe72a9-d373-4fb0-aa47-227fc6c3e552",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyDatabases.gpyDB.gpyDBnew import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f2eb02-02fb-4cd9-8494-de45e5a555c0",
   "metadata": {},
   "source": [
    "*NOTE: It is pretty slow to initialize two important GAMS related parts of the database. The ```gams.GamsWorkspace``` and the ```gams.core.numpy.gams2numpy.Gams2Numpy``` classes. This means that everytime we initialize a database with new instances of the two, it takes roughly 1/4 second. Thus, it can be quite advantageous not to initialize new instances of the two too often.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e742e5-7c30-4ff9-ad9a-7b78ca203335",
   "metadata": {},
   "source": [
    "## 1. GpyDB tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9207cf-78f0-42a3-bdea-e2fcf179ef26",
   "metadata": {},
   "source": [
    "Default working folder and data folders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96b90d27-52aa-4cc8-b64d-4ff184c392ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "work_folder = os.path.join(os.getcwd(),'workFolder')\n",
    "data_folder = os.path.join(os.getcwd(), 'testdata')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba0a3e4-299f-4a0a-a50a-3c78da6339d3",
   "metadata": {},
   "source": [
    "### 1.1. Init methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1fb85e-729e-45b9-b086-f4a9f8440805",
   "metadata": {},
   "source": [
    "We can initialize the database in several ways. The init methods are implemented in a multiple-dispatch like fashion, so it shouldn't impede the speed of initialization. The following covers the basics:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5509595c-794b-4d49-bfd4-4cbe65f0fd1b",
   "metadata": {},
   "source": [
    "#### i. From GamsDatabase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c63e96-3482-40c9-9f92-d9fdefe5980e",
   "metadata": {},
   "source": [
    "To load a GamsDatabase, we need a ```gams.Workspace```. We can add a new one using the staticmethod:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8745467b-9d5b-4dc0-b6d8-0cac98dd4bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = GpyDB.initWs(work_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4947ace-46ca-4879-a44f-41cd3ef275ed",
   "metadata": {},
   "source": [
    "Next, let us say that we already have a GamsDatabase open (here we load one from a gdx file):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c6024af-11c7-407a-80af-69d6d8bf85e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'testdb'\n",
    "gdxStr = os.path.join(data_folder,f'{name}.gdx')\n",
    "dbGms = ws.add_database_from_gdx(gdxStr, database_name = name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d041ea-48ae-4412-9f08-afce815d81df",
   "metadata": {},
   "source": [
    "We can initialize the GpyDB as a wrapper around  this database by calling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3707171-3df9-4e5e-bebe-a2e56a8f1174",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = GpyDB(dbGms, alias = None, data_folder = data_folder, dropattrs = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018512b9-6a50-4e52-bf2d-00db1e8e9fc1",
   "metadata": {},
   "source": [
    "In this case, we can only add the options (defaults in parenthesis):\n",
    "* ```alias = None```: Update specification of aliases (we'll return to this later).\n",
    "* ```data_folder = os.getcwd()```: Specification of where to store data if exporting it.\n",
    "* ```dropattrs = ['database','ws','g2np','gmd'].copy()```: What attributes of the class not to include when exporting it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e046f7e-675a-4cf8-961a-1780298ad686",
   "metadata": {},
   "source": [
    "We note that a number of attributes are set automatically: These cannot be adjusted in the ```__init__``` call, but may be adjusted later:\n",
    "* ```self.name```: Inherited from the GamsDatabase.\n",
    "* ```self.ws```: Inherited from the GamsDatabase.\n",
    "* ```self.g2np```: Instance of ```gams.core.numpy.gams2numpy.Gams2Numpy``` class that is required when working with gams data. To save time when initializing, all instances rely on the same instance of this class that is created when we import the packag. *Note: You need to adjust this instance, if you do not want to work in the default installation of GAMS (if you have more than one). See the online documentation for the GAMS Python API for more.*\n",
    "* ```self.gmd```: Instance of ```gpyDB.readGmd``` that is used when importing/exporting data from GAMS to Python.\n",
    "* ```self.series```: ```gpyDB.SeriesDB``` instance that is read from the ```GamsDatabase```."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6659898-02da-435c-bb51-3867c6d5730e",
   "metadata": {},
   "source": [
    "We export this as a pickle (here using default options):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8759de27-985f-49bc-aaa4-9a04271a5d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.export(name = None, repo = None) # name defaults to self.name, repo defaults to self.data_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb6a6b8-074f-49c2-b6f1-8f5c6bb71afb",
   "metadata": {},
   "source": [
    "Note that, when exporting data, we automatically drop the attributes in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6243ae00-52e1-4df4-ae42-d579a6bfb355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['database', 'ws', 'g2np', 'gmd']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.dropattrs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24a27ba-6139-42d5-8a6f-d7327ff335e0",
   "metadata": {},
   "source": [
    "The default behavior here is to keep the data stored in the python version from ```self.series``` instead of ```self.database```. If we insist on keeping the gdx data, we can always write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "258a0f08-1d0f-41a6-bcca-9674d3d1178b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# db.dropattrs = [k for k in db.dropattrs if k != 'database']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f076e08e-66d8-45bf-b7f8-60b750359dc7",
   "metadata": {},
   "source": [
    "If we do this, any call to the pickle module will start by writing a gdx file with the database and store it in the specified data folder. Then, when loading the pickle again, the database will be read in to the ```self.database``` attribute. This is a workaround that is required as the gams instances are generally not pickleable (Python does not automatically know how to store it)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680929f0-c857-411d-a274-83b314a4d6a8",
   "metadata": {},
   "source": [
    "#### ii. From Pickle "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b203c8eb-6617-4440-8997-ca245fc251e2",
   "metadata": {},
   "source": [
    "We can load the GpyDB from the pickled data using the path for the pickle. The only thing that we can adjust in the init call when using the pickled data is whether to adjust the workspace and aliases. In this case, we open the data in the existing workspace:\n",
    "\n",
    "*Note: The pickled data should always be loaded using the ```__init__``` method as outlined here - not using the standard load method from the pickle module (this is called \"under the hood\").*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c92bb791-4b0c-4046-a070-adbc234d0624",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcklStr = os.path.join(data_folder, name)\n",
    "dbPickled = GpyDB(pcklStr, ws = ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e85f66-29a0-4684-8f20-de0ab658142a",
   "metadata": {},
   "source": [
    "Note that the pickle will try to open the database with the name ```testdb``` (as specified in the initialization). However, as we also want to reuse the GamsWorkspace, we will automatically get a \"versionized name\" for the database (GAMS requires unique names for all databases in the workspace):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a07ae495-43ef-4e8a-97ca-60e4d368db24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'testdb__v1'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbPickled.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63f19b45-5f00-4a7a-b8b9-968445157051",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'database': <gams.control.database.GamsDatabase at 0x1cd9cecd950>,\n",
       " 'ws': <gams.control.workspace.GamsWorkspace at 0x1cd9cecc750>,\n",
       " 'work_folder': 'C:\\\\Users\\\\sxj477\\\\Documents\\\\GitHub\\\\pyDatabases\\\\workFolder',\n",
       " 'name': 'testdb',\n",
       " 'g2np': <gams.core.numpy.gams2numpy.Gams2Numpy at 0x1cd9cabee90>,\n",
       " 'data_folder': 'C:\\\\Users\\\\sxj477\\\\Documents\\\\GitHub\\\\pyDatabases\\\\testdata',\n",
       " 'dropattrs': ['database', 'ws', 'g2np', 'gmd'],\n",
       " 'gmd': <pyDatabases.gpyDB.database.readGmd at 0x1cd9ae77290>,\n",
       " 'series': <pyDatabases.gpyDB.gpyDBnew.SeriesDB at 0x1cd99ec28d0>}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c528c2-b8c6-4329-bb16-4076a0f88617",
   "metadata": {},
   "source": [
    "#### iii. From a GpyDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02498628-ff15-4cdb-ab9a-ad614100dbf2",
   "metadata": {},
   "source": [
    "We can also initialize it from another ```GpyDB```. This creates a copy of all attributes *except*  three gams related attributes ```ws, gmd, database```. If we do not provide a workspace, this inherits the one from the other database. The ```gmd``` and ```database``` attributes are then copied within this workspace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d447866e-9652-4945-9a29-5e3dfd0c496e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbFromGpyDB = GpyDB(db) # create copy of all except the four gams-related attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4259f84-8872-4b07-b2a8-bb83c2ceff00",
   "metadata": {},
   "source": [
    "*The workspace is now inherited:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b28eed5-b2b4-4ac3-b419-02d7cab24fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbFromGpyDB.ws is db.ws"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3ea2fd-cdec-4c82-b754-8e66822d1102",
   "metadata": {},
   "source": [
    "*The self.database is a copy - and the name is versionized to exist in the same workspace:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb1e78a2-7a84-41b6-a0f6-3ce8ee8e6830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('testdb__v2', False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbFromGpyDB.name, dbFromGpyDB.database is db.database # versionized name and copy of the database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4bb6cf-fcef-4ce2-9bf1-d1e345d2dcc6",
   "metadata": {},
   "source": [
    "Using the ```ws``` option, we can e.g. start in a new workspace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2022f15f-0dc7-428e-a5b1-f759e9c54e18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbFromGpyDB_newWs = GpyDB(db, ws = work_folder) # copy GpyDB in new workspace\n",
    "dbFromGpyDB_newWs.ws is db.ws"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30019b6a-2f66-4a93-92d3-b711f0847359",
   "metadata": {},
   "source": [
    "*Note: The method ```self.copy(ws = None, **kwargs)``` relies on this exact method to produce a copy:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a53a79bc-1542-4a30-a378-ce5381a8f61d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copiedDatabase = db.copy(ws = dbFromGpyDB_newWs.ws)\n",
    "copiedDatabase.ws is dbFromGpyDB_newWs.ws"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f9d7bb-11a3-4c8d-9aee-ead73f7c54ab",
   "metadata": {},
   "source": [
    "#### iv. From other database types:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8b96b6-5ecf-4f29-8f74-75b50c8a4042",
   "metadata": {},
   "source": [
    "Alternatively, we can initialize the GpyDB with information e.g. on the series or database attributes. This is done by passing ```obj=None``` as the first input and instead providing a ```db``` input. Beyond this argument, we can provide the following kwargs:\n",
    "* ```name```: Name of the ```GpyDB``` instance.\n",
    "* ```ws```: Works as in the other init types (can either reference an existing workspace, None (defaults to ```os.getcwd()``` then), or a string (indicating a repository to use).\n",
    "* ```data_folder```: where to export stuff.\n",
    "* ```dropattrs```: what to drop before exporting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1cc42fef-b331-4104-ac00-8221909ecf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbFromSeries = GpyDB(obj = None, db = db.series, ws = db.ws, name = 'NewName')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b4a800-4f8a-48ab-99d9-d92ded7dca20",
   "metadata": {},
   "source": [
    "Note that the this series is not copied but added directly as the ```self.series``` database, i.e. symbols are now the same across the two databases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "674ca841-7400-4dfd-afb2-e177955eb046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbFromSeries['i'] is db['i']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f901da07-8059-4a53-b8a1-c94233268bf5",
   "metadata": {},
   "source": [
    "We can also do this with a simple ```dict``` database with gpy symbols, for instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dfec1bb1-a10b-416c-a282-2be162582d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbFromDict = GpyDB(obj = None, db = db.series.database, ws = db.ws, name = 'NewName')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9a0831-57f9-4907-8418-85a2bddb1efb",
   "metadata": {},
   "source": [
    "Finally, we can pass a ```GamsDatabase``` to this argument. Recall that if we passed this type as the ```obj``` argument, the ```GpyDB``` \"wrapped\" around this, i.e. it draws on this database directly as ```self.database```. If we use ```db = GamsDatabase``` instead, we open a new database drawing on this as a source:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "66461405-4b8c-4e5a-964f-0b28fa7a2086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbFromGams_sourceDB = GpyDB(obj = None, db = db.database, ws = db.ws, name = 'otherName')\n",
    "dbFromGams_sourceDB.database is db.database # if we initialized with obj = db.database this would be true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa92765-685d-4c44-9b4c-bbfdd9c372e9",
   "metadata": {},
   "source": [
    "### 1.2. Merge, export, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b495f99-d6b3-410c-a00c-5c5205b7c88a",
   "metadata": {},
   "source": [
    "*Merge internal with ```priority = 'second'```:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73e5604e-039a-4688-98a7-7fbb298706e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.mergeInternal(priority = 'second') # overwrite existing symbols\n",
    "db.database.export('test1.gdx') # test that exports look as expected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c19b878-b7c6-4a71-bb8e-997199c16741",
   "metadata": {},
   "source": [
    "*Merge internal with ```merge = 'replace'```: This creates a new ```GamsDatabase``` in the workspace, where everything is added to:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3884343b-9e3e-4dc5-a42a-cb710bbdd64f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'testdb': 0,\n",
       " 'testdb__v1': 0,\n",
       " 'testdb__v2': 0,\n",
       " 'NewName': 0,\n",
       " 'NewName__v1': 0,\n",
       " 'otherName': 0,\n",
       " 'test2': 0}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.mergeInternal(priority = 'replace', name = 'test2')\n",
    "db.database.export('test2.gdx')\n",
    "db.ws._gams_databases # the original workspace still contains the original database, but the main db in the GpyDB class is the new one 'test2__v1'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e97e415-993b-4503-8add-2db9b79aa4ce",
   "metadata": {},
   "source": [
    "*Test pickle with gdx data included:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5fbae8f5-180f-4696-991e-f247a18c83d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.dropattrs = [k for k in db.dropattrs if k !='database'] # remove 'database' from list of attributes NOT to keep\n",
    "db.export(name = 'GpyDBwithGdx') # export with gdx database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbacefb-f1fc-4021-8441-67d10080638b",
   "metadata": {},
   "source": [
    "*As the gdx database is not pickleable, it is written to a separate file in the data folder and loaded again if we pickle this:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f7962e2-79fe-47be-a312-f98a2d969f69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alias_set': <Swig Object of type 'void *' at 0x000001CD9CECB3F0>,\n",
       " 'alias_map2': <Swig Object of type 'void *' at 0x000001CD9CECBD20>,\n",
       " 'i': <Swig Object of type 'void *' at 0x000001CD9CECA280>,\n",
       " 'j': <Swig Object of type 'void *' at 0x000001CD9CECAEE0>,\n",
       " 'alias_': <Swig Object of type 'void *' at 0x000001CD9CECBA50>,\n",
       " 'map': <Swig Object of type 'void *' at 0x000001CD9CECB330>,\n",
       " 'var': <Swig Object of type 'void *' at 0x000001CD9CECB7B0>,\n",
       " 'var1d': <Swig Object of type 'void *' at 0x000001CD9CECAE50>,\n",
       " 'param': <Swig Object of type 'void *' at 0x000001CD9CECA490>,\n",
       " 'scalar': <Swig Object of type 'void *' at 0x000001CD9CECBF00>,\n",
       " 'pscalar': <Swig Object of type 'void *' at 0x000001CD9CEC8F00>,\n",
       " 'subset': <Swig Object of type 'void *' at 0x000001CD9CEC8EA0>}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbPickled_v2 = GpyDB(os.path.join(db.data_folder, 'GpyDBwithGdx'))\n",
    "dbPickled_v2.gmd.symbols # symbols from database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e64e73f-6f21-4e59-8f40-0da104ada59a",
   "metadata": {},
   "source": [
    "### 1.3. Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac291f6e-9b98-4720-bf5a-fe5dd68de03b",
   "metadata": {},
   "source": [
    "#### Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a8054b6-81ab-4735-a45f-8a2e6a4c2cbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'j': Index(['jj'], dtype='object', name='alias_map2')}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.aliasDict # map from original set to aliases\n",
    "# db.aliasDict0 # includes the original set in the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "135ee144-706b-4047-a413-041b35df4d55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'jj'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.alias_notin_db # what aliases are not also included in the database as symbols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67a2389-5f08-421f-8a1f-6698ab55e843",
   "metadata": {},
   "source": [
    "#### Get/set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed9e401-a62b-4650-b105-f3658fcc43c6",
   "metadata": {},
   "source": [
    "Add symbols to the ```self.series``` database using ```self.__setitem__``` method. This automatically calls the ```gpy``` class, so we can set items either using their pandas/python pendant or the gpy symbols:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "817a1277-368a-4aa8-aba3-3fa0fdc6ed36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['set', 'subset', 'map']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db['newSet'] = pd.Index([0,1], name = 'newSet')\n",
    "db['newSubset'] = pd.Index([0], name = 'newSet') # If the domain of the index does not coincide with the given name in the database --> subset\n",
    "db['newMap'] = pd.MultiIndex.from_product([db('j'), db('newSet')]) # the .__call__() method accesses the pandas/python part of the symbol directly\n",
    "[db[k].type for k in ('newSet','newSubset','newMap')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6039fe41-d1ff-400c-952e-bc1d4ec19b8d",
   "metadata": {},
   "source": [
    "The ```self.__call__``` method accesses the ```self.vals``` part of the ```gpy``` symbols, i.e.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6e0bc909-033b-4dc2-a140-6deb7033b0e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db['newSet'].vals is db('newSet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d810b0b5-6f2a-4508-856b-8335b6cf8b68",
   "metadata": {},
   "source": [
    "The ```self.__call__``` and ```self.__getitem__``` methods allows us to access aliased sets as well. For instance, the alias ```'jj'``` is not defined as a symbol in the ```self.series``` database, but calling this we access the original set ```'j'```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "10526e33-82d6-4b9b-9ec1-9c1fa5bae315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db['jj'] is db['j'] # the self.__getitem__ method accesses the parent set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7dbe85d7-7178-4c08-8818-1278c0607dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([  1,   0,   2,   3,   4,   5,   6,   7,   8,   9,\n",
       "       ...\n",
       "       990, 991, 992, 993, 994, 995, 996, 997, 998, 999],\n",
       "      dtype='int32', name='jj', length=1000)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db('jj') # the get method accesses parent set + adjusts name of index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdb10c4-a400-40b2-8f2e-e92eaff3e1fc",
   "metadata": {},
   "source": [
    "#### Alias methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df9038d-6e52-4949-886a-7411fe37f2ed",
   "metadata": {},
   "source": [
    "The method ```self.alias(x, idx = 0)```: \n",
    "* If ```x``` is not aliased, but a set and ```idx=0```: ```return x```.\n",
    "* If ```x``` is either an aliased set or a parent set to one, this returns the parent set when ```idx = 0``` as default, while for ```idx>0``` this returns the aliased sets (idx is passed to ```self.aliasDict0```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f0512180-303b-449f-8a38-db7e11d1342f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.alias('i') # 'i' is a set, so this works even though it is not aliased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "35319f2b-31ed-4ee7-b3c5-6d3210d7f243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This trows a TypeError, because i is not alised\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    db.alias('i', idx = 1)\n",
    "except TypeError:\n",
    "    print('This trows a TypeError, because i is not alised')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5c194c59-833c-4736-9f0e-4aaa9f3d493d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'j' == db.alias('j') == db.alias('jj') # aliased sets return the same object no matter if it is a parent set or the aliased one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "28787f78-6239-4746-8a30-fc885ddc89f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'jj' == db.alias('j',idx = 1) == db.alias('jj',idx=1) # if idx = 1 this returns the first aliased set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfdfcce-6937-4b3a-a5ee-9f1cc38ed54f",
   "metadata": {},
   "source": [
    "#### Other"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5befb4-3e46-4fbb-9ded-ed2adca1edb0",
   "metadata": {},
   "source": [
    "The method ```self.getTypes(types)``` returns a subset of the ```self.symbols``` property based on the types (iterative arg.) that are passed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "641a5249-6402-4e4b-961c-32701c0a8896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alias_set': <pyDatabases.gpyDB.database.gpy at 0x1cd9cf3b0d0>,\n",
       " 'alias_map2': <pyDatabases.gpyDB.database.gpy at 0x1cd9a25e350>,\n",
       " 'i': <pyDatabases.gpyDB.database.gpy at 0x1cd9cf45450>,\n",
       " 'j': <pyDatabases.gpyDB.database.gpy at 0x1cd9cf17fd0>,\n",
       " 'newSet': <pyDatabases.gpyDB.database.gpy at 0x1cd9cf7ea50>}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.getTypes(['set']) # get sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "95184c99-a459-4560-be8d-4058cc344d8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alias_set': <pyDatabases.gpyDB.database.gpy at 0x1cd9cf3b0d0>,\n",
       " 'alias_map2': <pyDatabases.gpyDB.database.gpy at 0x1cd9a25e350>,\n",
       " 'i': <pyDatabases.gpyDB.database.gpy at 0x1cd9cf45450>,\n",
       " 'j': <pyDatabases.gpyDB.database.gpy at 0x1cd9cf17fd0>,\n",
       " 'scalar': <pyDatabases.gpyDB.database.gpy at 0x1cd9cf17090>,\n",
       " 'newSet': <pyDatabases.gpyDB.database.gpy at 0x1cd9cf7ea50>}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.getTypes(['set','scalarVar']) # get scalar variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051e5c50-147c-42f4-bb52-748a6501d366",
   "metadata": {},
   "source": [
    "The method ```self.domainsUnique(x)``` returns the unique domains a symbol is defined over, replacing aliased sets with their parent sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eab0659c-25e1-495d-a281-46a6f4947fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'j']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.domainsUnique('var')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0d29ad-2e8d-4657-bdcd-a8d419caab1d",
   "metadata": {},
   "source": [
    "The method ```self.varDom(set_, types = None)``` returns a dictionary with keys = sets and aliases and values = list of symbols of 'types' that are defined over these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f38c0114-ab2d-40b3-a2e8-9861b05318bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'i': ['var', 'var1d', 'param']}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.varDom('i') # the default is to look for types ['var','par']. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "642a9fe1-8506-4707-a16b-9af19df4acbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'i': ['map', 'var', 'var1d']}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.varDom('i', types = ['var','map'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a26a13a-61de-491f-b902-0d211a6f9715",
   "metadata": {},
   "source": [
    "## 2. Other classes from ```gpyDB```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04ccb58-d7e3-4686-a962-e0de9edbafd5",
   "metadata": {},
   "source": [
    "### 2.1. ```DbFromExcel```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6912220e-0840-48f1-8735-148ba27a1121",
   "metadata": {},
   "source": [
    "Small calss that reads in excel data as dicts of ```gpy``` symbols. Data has to be arranged in a particular way for this to work. Examples are given in the ```test_read.xlsx``` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2f30984c-522a-4923-bba4-b741653a6190",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = os.path.join(os.getcwd(), 'testdata','test_read.xlsx')\n",
    "kwargs = {k: f'_{k}' for k in ('set','subset','map','var','scalarVar','var2D')}\n",
    "db_ = DbFromExcel.dbFromWB(file, kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515926e4-18e1-4a0b-96cc-ed5982129f89",
   "metadata": {},
   "source": [
    "The kwargs indicate key = method to apply when reaing the data, value = sheet or list of sheets to iterate through. The syntax for loading several sheets calling the same method is done by adding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5c444723-0722-4f38-83c8-e3bb6bc75d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs['set'] = ['_set','extraset'] # iterable of sheetnames\n",
    "db_ = DbFromExcel.dbFromWB(file, kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dbe937-6fcc-4894-87e9-98fd213a1282",
   "metadata": {},
   "source": [
    "### 2.2. ```AggDB```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad87a152-d91f-4a7e-bf53-8cb2419c5026",
   "metadata": {},
   "source": [
    "Small class that can be used to aggregate the database. The class contains a handfull of methods that are called when doing the \"main\" aggregation method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6744cc8-877f-4b51-97b8-415ef637b987",
   "metadata": {},
   "source": [
    "*Re-read the clean database version:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c40e68f4-7e8d-4b98-8163-c05a3cc58c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = GpyDB(name = 'test1', db = gdxStr, ws = work_folder, data_folder = data_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb235a3-b3d0-4eaa-9141-baba65e3ceb1",
   "metadata": {},
   "source": [
    "To make sure that our alias method work, define a couple of extra symbols over the alias as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b794254f-d99c-45a9-9c60-5382944dc0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "jj = pd.Index(np.roll(db('map').get_level_values('j').values, 1), name = 'jj')\n",
    "db['mapWithAlias'] = pd.MultiIndex.from_arrays([db('map').get_level_values(0), db('map').get_level_values(1), jj]).sort_values()\n",
    "db['subsetWithAlias'] = jj[0:2].rename('subsetWithAlias')\n",
    "db['varWithAlias_1'] = pd.Series(1.5, index = db('mapWithAlias')) \n",
    "db['varWithAlias_2'] = pd.Series(0.5, index = adj.AdjAliasInd(db('map'), alias = {'j':'jj'})[0:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1746be-0fe0-4d34-98a0-576148e3dd1f",
   "metadata": {},
   "source": [
    "#### 2.2.1. Update set elemetns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b7f3bd-c6c2-4981-90bb-b36c7f904e26",
   "metadata": {},
   "source": [
    "The first method takes a mapping from old to new set values and updated the values in indices used throughout the database. We note that this is generally *not* used to aggregate databases, i.e. we prefer not to use a mapping that reduces the number of set elements, but merely renames them. However, the method does work even if this is the case. For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "17c53cac-435a-4757-a936-6e811ee3240c",
   "metadata": {},
   "outputs": [],
   "source": [
    "setName = 'j'\n",
    "ns = {1: 0, 2:0, 3:0}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce19b6d-85e7-46e1-877d-ce0bb2ccda2a",
   "metadata": {},
   "source": [
    "There are two things to be aware of here: \n",
    "* We may use ```rul = True``` if we want to remove unused levels in all indices before mapping to the new values (see ```pd.Index.remove_unused_levels```).\n",
    "* If the namespace mapping (```ns```) that we apply implies non-unique combinations, we generally ensure that all sets, subsets, and mappings are forced to unique combinations, whereas we keep all records of parameters and variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bf882690-a7e7-40b3-a43f-c65332c77d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_newSetValues = AggDB.updSetElements(db.copy(), setName, ns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fa8d0a-b490-46d4-bb8c-ada8147d14b3",
   "metadata": {},
   "source": [
    "So, the mapping 'map' includes fewer elements than before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "590d4261-05de-410b-8965-e03b9d4b69c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(db('map'))-len(db_newSetValues('map'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a83e38-5ac3-4b1f-a79b-366f08f33a6f",
   "metadata": {},
   "source": [
    "Whereas the variable 'var' that is defined over the same mapping does not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "396eb0e3-1eeb-426c-aff8-994084bef1b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(db('var'))-len(db_newSetValues('var'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462f3a30-b43e-40b5-8e5d-fce2d2c33438",
   "metadata": {},
   "source": [
    "#### 2.2.2. Update set names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959df1c1-76da-4903-8344-f2e1c2fb0bf2",
   "metadata": {},
   "source": [
    "This method changes the set name used throughout all symbols. For instance, let us say that we want to rename the set $i$ to $k$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e75d5b5a-718d-44da-abea-6a9315d1572a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = {'i':'k'}\n",
    "db_newSetNames = AggDB.updSetNames(db.copy(), ns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc328303-3cb6-4478-8e10-34bdc1164950",
   "metadata": {},
   "source": [
    "#### 2.2.3. Update sets from symbols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77aca018-b24c-40b2-aff3-93c3e35929a6",
   "metadata": {},
   "source": [
    "This infer set values from the symbols that are otherwise defined in the database. This can be used if we load information e.g. on variables or parameters, and subsequently want to define the underlying sets as well (e.g. because GAMS usually requires this):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b0fc3172-8abc-4658-90eb-774666ed6f11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyDatabases.gpyDB.gpyDBnew.GpyDB at 0x1cd99ed6610>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_updSetsFromSyms = db.copy() # create copy\n",
    "AggDB.updSetsFromSyms(db, types = ['var','par'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e3701e-3eab-45d3-af02-f99416feae3e",
   "metadata": {},
   "source": [
    "We have the following options when doing this:\n",
    "* ```types = None```: The type of symbols to infer set definitions from. When ```None``` this defaults to ```['var','par']``` definitions.\n",
    "* ```clean = True```: If ```True```, it starts by empyting all set, subset, and map definitions.\n",
    "* ```clean_alias = True```: Reset alias settings (stored in ```self.db['alias_']``` multiindex).\n",
    "* ```ignore_alias = False```: If ```False```, this does not add aliased sets to the database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2d6311-6a13-4171-97fa-ee9dbc7addf9",
   "metadata": {},
   "source": [
    "#### 2.2.4. Subset database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048d03e2-045e-41af-b712-ce7c379cdbcb",
   "metadata": {},
   "source": [
    "This adjusts all symbols in the database based on an index, we provide. For instance, say that we want to exclude some elements from the $j$ index across all symbols:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f077f697-d003-471f-9905-c0ea5893ad3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "i  j\n",
       "1  1    10.0\n",
       "   0    10.0\n",
       "   2    10.0\n",
       "Name: var, dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_subsetDB = AggDB.subsetDB(db.copy(), pd.Index(db('j')[0:3])) # remove all but the first 4 elements in the 'j' index - for all symbols in the database\n",
    "db_subsetDB('var') # all symbols including e.g. variables are \"subsetted\" in this manner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71836e3-a664-493c-be35-9e9c6eb1fc8a",
   "metadata": {},
   "source": [
    "#### 2.2.5. Aggregate database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ce1d4a-0e72-4c6f-aa72-d05efb98f7fc",
   "metadata": {},
   "source": [
    "This aggregates all symbols according to a mapping from old set elements to new ones. Contrary to the method ```updSetElements```, this method is designed to change the number of set elements in the various indices, and to handle non-unique combinations of variable entries etc.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2b5477-71c4-41fd-ba9b-6ae35fef2d19",
   "metadata": {},
   "source": [
    "Say, for instance, that we want to aggregate the set $j$ into intervals of 10's:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6940658e-b8ee-4017-853d-ee70f5170f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = pd.MultiIndex.from_arrays([db('j'), np.round(db('j')+5.1, -1).astype(int).rename('agg_j')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5723826-79f8-41e3-80d3-fc5e17c0f077",
   "metadata": {},
   "source": [
    "We need to decide what to do with the variables that are now aggregated. Currently, we have implemented a handful of methods: ```Sum, Mean, WeightedSum, SplitDistr, Lambda```. As a default, the method will use the simple ```Sum``` method. We can adjust this by specifying a dictionary as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "eb758ec7-3c41-42dd-8bb3-79dd46cac429",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggLike = {'var': {'func': 'Mean', 'kwargs': {}}}\n",
    "db_agg = AggDB.aggDB(db.copy(), mapping, aggBy = None, replaceWith = None, aggLike = aggLike) # default options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b262896c-6938-4e47-995b-068357951398",
   "metadata": {},
   "source": [
    "We can also use this, in principle, to disaggregate a database. Let us, for simplicity, assume that we want to split up a single set element in the $j$ set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d9c23210-c9f0-469c-a94a-23e8582207b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = pd.MultiIndex.from_arrays([db('j'), db('j').rename('disagg_j')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31120a70-bb44-49ac-96eb-6297efc0ffd5",
   "metadata": {},
   "source": [
    "## 3. Methods from ```gpyDB.database.py```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a47813-fda7-4f85-93ee-31abcecb63f4",
   "metadata": {},
   "source": [
    "This includes classes that transfers data between Python (```gpy```) and GAMS (```GamsDatabase, Gmd```). Most notably, we have the following classes:\n",
    "1. ```gpy```: Customized symbol class that ```GpyDB``` draws on.\n",
    "2. ```readGmd``` (or ```gpyFromGmd```): Transfer data from ```GamsDatabase``` to ```gpy```-like symbols. Draws on the fast methods from ```gams.core.gmd```.\n",
    "3. ```gmdFromGpy```: Transfer data from ```gpy``` format to ```GamsDatabase``` symbols. Draws on the fast methods from ```gams.core.gmd```.\n",
    "4. ```gpyFromGt```: Transfer data using ```gams.transfer.Container``` to ```gpy```-like symbols. Pretty fast (not as fast as ```readGmd``` though). \n",
    "5. ```gtFromGpy```: Populate a ```gams.transfer.Container``` database using ```gpy``` symbols.\n",
    "6. ```MergeSyms```: Merge symbols from gams or gpy databases.\n",
    "\n",
    "As GAMS models rely on ```GamsDatabase```, however, we will rarely use classes 5-6."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222aa4f6-9129-4522-81cc-e0d593e8b14f",
   "metadata": {},
   "source": [
    "Merge methods:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca303fa8-eb5a-4cd6-86c1-240693331143",
   "metadata": {},
   "source": [
    "```python\n",
    "class readGmd:\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e2c7ba-ab50-45df-be1d-ebbe91e3f6ba",
   "metadata": {},
   "source": [
    "Methods for reading a gams database (```self.database``` from the ```GpyDB``` instance) to dict of ```gpy``` symbols. This is class that is used when initializing ```GpyDB``` from a GamsDatabase.\n",
    "* The ```self.__call__``` method returns a dictionary of ```gpy``` symbols that represents the entire database.\n",
    "* The ```self.gpy(symbol)``` method returns a ```gpy``` from the symbol input (needs to be a ```Swig Object```). These symbols can be accessed in dictionary from ```self.symbols```."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7854b910-0033-4449-a85f-b57fb322e262",
   "metadata": {},
   "source": [
    "```python\n",
    "class gpyFromGt:\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d72ea89-f8c5-4893-a99d-681b8281ff35",
   "metadata": {},
   "source": [
    "Does the same thing as ```readGmd```, but for a ```gams.transfer.Container``` database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348085c3-b7ce-4d7c-bd99-cceaf59664b3",
   "metadata": {},
   "source": [
    "```python\n",
    "class gtFromGpy:\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e5f888-11c0-4cc2-a617-3f2a62f1d11f",
   "metadata": {},
   "source": [
    "Inverse to ```gpyFromGt```."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9886dcc8-8f1b-4d09-80fc-9dbacc9ed0de",
   "metadata": {},
   "source": [
    "```python\n",
    "class gmdFromGpy\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4267115a-ebc9-4e19-9ce5-634b4036bdd1",
   "metadata": {},
   "source": [
    "Inverse methods to ```readGmd``` class. This has method for adding symbols to GamsDatabases, adjusting them, and adding-or-merging.\n",
    "* ```self.db(dbGpy, dbGmd, g2np, merge = True)```: Merge symbols from dbGpy (populated with ```gpy``` symbols) into dbGmd (```GamsDatabase```).\n",
    "* ```self.initDb(dbGpy, dbGmd, g2np)```: Like ```self.db```, but it assumes that ```dbGmd``` is empty / does not have any of the symbols from ```dbGpy``` before doing so.\n",
    "* ```init(symbol, db)```, ```add(symbol, db, g2np)```, ```adjust(symbol, db, g2np)```: Static methods that initialize, add, and adjust symbols in a database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e48f653-1721-472f-bcfb-26febba59e20",
   "metadata": {},
   "source": [
    "### 3.1. MergeSyms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b717ada4-3c4c-44f8-a5c9-4db007c1360e",
   "metadata": {},
   "source": [
    "The class is set up to merge symbols from gpy or gmd database types. The method ```MergeSyms.merge``` is a robust version that works with the four combinations. \n",
    "\n",
    "**Note that all these methods work *inplace* meaning that you will alter the symbols along the way**. (*This is by design, as the symbols from the gmd database only exists in conjunction with the database itself - thus returning a copy is meaningless unless we initialize an entire new database*)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be59e744-0733-42b5-aaaa-43a1a8e896f1",
   "metadata": {},
   "source": [
    "*Merge two gpy symbols:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "191b584c-6d9f-44d7-9e14-274bf24dbf94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyDatabases.gpyDB.database.gpy at 0x1cd9cf45f90>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MergeSyms.merge(db['var'], db['param'], priority = 'first') # merge the two, and keep values from the first symbol if they overlap\n",
    "# MergeSyms.merge(db['var'], db['param'], priority = 'second') # merge the two, and keep values from the second symbol if they overlap\n",
    "# MergeSyms.merge(db['var'], db['param'], priority = 'replace') # merge the two and only use values from the second symbol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd50005-0f40-4da1-92ec-b1296d8c01ea",
   "metadata": {},
   "source": [
    "*Merge gpy and gmd symbol:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "44b661c5-e212-4586-8da3-a892acfd5437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyDatabases.gpyDB.database.gpy at 0x1cd9cf45f90>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MergeSyms.merge(db['var'], db.gmd, name = 'var', priority = 'first') # merge the two and keep values from gpy symbol if they overlap\n",
    "# MergeSyms.merge(db['var'], db.gmd, name = 'var', priority = 'second') # merge the two and keep values from gmd symbol if they overlap\n",
    "# MergeSyms.merge(db['var'], db.gmd, name = 'var', priority = 'replace') # merge the two and only use values from the second symbol "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acea8ca-1e27-4b08-98e5-bbfcae86381a",
   "metadata": {},
   "source": [
    "*Merge gmd and gpy symbols:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1c580848-d6aa-4d71-a08b-c1208eaef189",
   "metadata": {},
   "outputs": [],
   "source": [
    "MergeSyms.merge(db.gmd, db['var'], name = 'var', priority = 'first')\n",
    "# MergeSyms.merge(db.gmd, db['var'], name = 'var', priority = 'second')\n",
    "# MergeSyms.merge(db.gmd, db['var'], name = 'var', priority = 'replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c10b92-8d29-4ca4-8bdf-10938fd10f08",
   "metadata": {},
   "source": [
    "*Merge gmd and gmd symbols:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6608e164-0193-420c-b0aa-a54efaf171f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "MergeSyms.merge(db.gmd, db.gmd, name = 'var', priority = 'first')\n",
    "# MergeSyms.merge(db.gmd, db.gmd, name = 'var', priority = 'second')\n",
    "# MergeSyms.merge(db.gmd, db.gmd, name = 'var', priority = 'replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddaa983c-c030-43de-b2dc-3faddcc30ed6",
   "metadata": {},
   "source": [
    "### 3.2. MergeDbs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2354c963-1dad-49ad-a323-27b926b36c18",
   "metadata": {},
   "source": [
    "The class merges databases that are of the types ```GpyDB, SeriesDB, dict, readGmd``` (the dict should be a dictionary of ```gpy``` symbols). Once again, the method ```MergeDbs.merge``` is a version that works with combinations of the four. As with ```MergeSyms``` these methods all work inplace as well, i.e. we alter the databases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddb2432-fab6-473a-b264-a31e24ab61fd",
   "metadata": {},
   "source": [
    "*This is a very simple test of whether the merges work, as they are all essentially the same database (almost at least, the code above may have altered them slightly)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "93d39b2a-b768-49c9-b6fc-befcef938f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbs = [db, db.series, db.series.database, db.gmd]\n",
    "for dbi, dbii in itertools.product(dbs, dbs):\n",
    "    MergeDbs.merge(dbi,dbii)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b5772b-9823-4cc2-8b95-13bc8eb4345a",
   "metadata": {},
   "source": [
    "## 4. Methods from ```auxfuncs.py```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60742433-5ca7-492c-a272-6b30dc4b34dd",
   "metadata": {},
   "source": [
    "This section is loaded in all other modules and contains basic methods. It includes:\n",
    "* ```OrdSet``` class: Custom class with ordered sets.\n",
    "* ```adj``` class: Provides methods to (i) subset pandas with nested conditions, (ii) adjust indices with lags or aliased sets.\n",
    "* ```adjMultiIndex``` class: Methods used to adjust symbols defined over multiindices. This includes (i) broadcasting, (ii) applying multiindices to symbols that matches/expands sets they are defined over, (iii) appending symbols with pre-specified grids.\n",
    "* ```readSetsFromDb``` method: Reads in and defines sets/indices based on the ```pd.Index``` objects that variables/mappings are defined over."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
